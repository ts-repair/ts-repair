/**
 * Benchmark Types
 *
 * Type definitions for the ts-repair benchmark harness.
 * Used to compare scoring strategies and measure builder effectiveness.
 */

import type { RepairPlan, ScoringStrategy } from "../output/types.js";

// ============================================================================
// Corpus Configuration
// ============================================================================

/**
 * A single entry in the benchmark corpus.
 * Represents a TypeScript project fixture to run benchmarks against.
 */
export interface CorpusEntry {
  /** Unique identifier for this corpus entry */
  name: string;

  /** Category of the fixture (for filtering and reporting) */
  category: "synthetic" | "builder-specific" | "real-world";

  /** Path to the tsconfig.json for this fixture */
  configPath: string;

  /** Expected outcome for validation */
  expectedOutcome: {
    /** Minimum acceptable error reduction ratio (0-1) */
    minErrorReduction: number;
    /** Target error reduction ratio (0-1) */
    targetErrorReduction: number;
    /** Builders expected to contribute to fixes */
    applicableBuilders: string[];
  };

  /** Optional metadata about the fixture */
  metadata?: {
    /** TypeScript error codes present in this fixture */
    errorCodes?: number[];
    /** Number of files in the project */
    fileCount?: number;
    /** Initial error count before repair */
    initialErrorCount?: number;
  };
}

/**
 * Configuration for the benchmark corpus.
 * Specifies which fixtures to include and how to filter them.
 */
export interface CorpusConfig {
  /** All corpus entries to consider */
  entries: CorpusEntry[];

  /** Optional filters to subset the corpus */
  filters?: {
    /** Only include fixtures from these categories */
    categories?: Array<"synthetic" | "builder-specific" | "real-world">;
    /** Only include fixtures that apply to these builders */
    builders?: string[];
    /** Exclude fixtures with more than this many initial errors */
    maxInitialErrors?: number;
  };
}

// ============================================================================
// Benchmark Configuration
// ============================================================================

/**
 * Configuration for a benchmark run.
 */
export interface BenchmarkConfig {
  /** The corpus of test fixtures to benchmark */
  corpus: CorpusConfig;

  /** Scoring strategies to compare */
  strategies: ScoringStrategy[];

  /** Whether to include high-risk fixes in the benchmark */
  includeHighRisk: boolean;

  /** Whether to enable telemetry collection */
  enableTelemetry: boolean;

  /** Number of iterations per fixture (for timing stability) */
  iterations: number;
}

// ============================================================================
// Timing Metrics
// ============================================================================

/**
 * Timing metrics for a benchmark run.
 */
export interface TimingMetrics {
  /** Total time for the run (ms) */
  totalMs: number;

  /** Time spent getting initial diagnostics (ms) */
  diagnosticsMs?: number;

  /** Total time spent on verifications (ms) */
  verificationMs?: number;

  /** Average time per verification (ms) */
  avgVerificationMs?: number;
}

// ============================================================================
// Per-Run Metrics
// ============================================================================

/**
 * Metrics collected for a single benchmark run.
 */
export interface RunMetrics {
  /** Number of errors before repair */
  initialErrors: number;

  /** Number of errors after repair */
  finalErrors: number;

  /** Error reduction ratio (initialErrors - finalErrors) / initialErrors */
  errorReduction: number;

  /** Total candidates generated across all diagnostics */
  candidatesGenerated: number;

  /** Number of candidates that were verified */
  candidatesVerified: number;

  /** Number of candidates pruned before verification */
  candidatesPruned: number;

  /** Number of fix steps applied */
  stepsApplied: number;

  /** Average delta (error reduction) per step */
  avgDeltaPerStep: number;

  /** Number of steps that caused regressions (introduced new errors) */
  regressionCount: number;
}

// ============================================================================
// Builder Metrics
// ============================================================================

/**
 * Metrics for a specific solution builder.
 */
export interface BuilderMetrics {
  /** Name of the builder */
  builderName: string;

  /** Number of diagnostics matched by this builder */
  diagnosticsMatched: number;

  /** Number of candidates generated by this builder */
  candidatesGenerated: number;

  /** Number of candidates from this builder that were verified */
  candidatesVerified: number;

  /** Number of candidates from this builder that were selected (applied) */
  candidatesSelected: number;

  /** Success rate: candidatesSelected / candidatesVerified */
  fixSuccessRate: number;

  /** Number of false positives (matches that didn't result in valid fixes) */
  falsePositives: number;

  /** False positive rate: falsePositives / diagnosticsMatched */
  falsePositiveRate: number;

  /** Average time to generate candidates (ms) */
  avgGenerationTimeMs: number;
}

// ============================================================================
// Strategy Metrics
// ============================================================================

/**
 * Aggregated metrics for a scoring strategy across all runs.
 */
export interface StrategyMetrics {
  /** The scoring strategy */
  strategy: ScoringStrategy;

  /** Total fixes applied across all runs */
  totalFixesApplied: number;

  /** Total errors fixed across all runs */
  totalErrorsFixed: number;

  /** Average error reduction ratio across all runs */
  avgErrorReduction: number;

  /** Rate at which the top-ranked candidate was selected */
  topCandidateSelectionRate: number;

  /** Total time across all runs (ms) */
  totalTimeMs: number;

  /** Average time per error fixed (ms) */
  timePerErrorFixed: number;
}

// ============================================================================
// Benchmark Run
// ============================================================================

/**
 * Results from a single benchmark run.
 */
export interface BenchmarkRun {
  /** Path to the tsconfig.json that was benchmarked */
  configPath: string;

  /** Scoring strategy used for this run */
  strategy: ScoringStrategy;

  /** The repair plan produced */
  result: RepairPlan;

  /** Timing metrics for this run */
  timing: TimingMetrics;

  /** Run metrics (error counts, candidates, etc.) */
  metrics: RunMetrics;

  /** Per-builder statistics for this run */
  builderStats: BuilderMetrics[];
}

// ============================================================================
// Strategy Comparison
// ============================================================================

/**
 * Comparison between two strategy runs on the same fixture.
 */
export interface StrategyComparison {
  /** Name of the fixture being compared */
  fixture: string;

  /** Results from the delta strategy run */
  delta: BenchmarkRun;

  /** Results from the weighted strategy run */
  weighted: BenchmarkRun;

  /** Which strategy performed better on this fixture */
  winner: "delta" | "weighted" | "tie";

  /** Detailed comparison metrics */
  comparison: {
    /** Difference in errors fixed (positive = weighted fixed more) */
    errorsFixedDiff: number;
    /** Difference in verifications performed (positive = weighted used more) */
    verificationCountDiff: number;
    /** Difference in total time (positive = weighted took longer, ms) */
    timingDiff: number;
  };
}

// ============================================================================
// Full Benchmark Results
// ============================================================================

/**
 * Complete results from a benchmark run.
 */
export interface BenchmarkResults {
  /** ISO timestamp when the benchmark was run */
  timestamp: string;

  /** Version of ts-repair used */
  version: string;

  /** Configuration used for this benchmark */
  config: BenchmarkConfig;

  /** All individual runs */
  runs: BenchmarkRun[];

  /** Comparison between scoring strategies */
  strategyComparison: {
    /** Aggregated metrics for delta strategy */
    delta: StrategyMetrics;
    /** Aggregated metrics for weighted strategy */
    weighted: StrategyMetrics;
    /** Overall winner based on error reduction */
    winner: ScoringStrategy;
    /** Statistical confidence in the winner (0-1) */
    confidence: number;
    /** Human-readable recommendation */
    recommendation: string;
  };

  /** Effectiveness metrics per builder */
  builderEffectiveness: Record<
    string,
    {
      /** Total diagnostics matched across all runs */
      totalMatches: number;
      /** Overall success rate (fixes applied / diagnostics matched) */
      successRate: number;
      /** Overall false positive rate */
      falsePositiveRate: number;
      /** Average generation time (ms) */
      avgTimeMs: number;
    }
  >;

  /** Summary of the corpus used */
  corpusSummary: {
    /** Total number of fixtures benchmarked */
    totalFixtures: number;
    /** Total initial errors across all fixtures */
    totalErrors: number;
    /** Total errors fixed across all runs */
    totalFixed: number;
    /** Error coverage by category */
    coverageByCategory: Record<string, number>;
  };
}
